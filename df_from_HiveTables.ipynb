{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and initiate findspark\n",
    "Then import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/usr/local/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instatiate SparkSession with Hive support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Python Spark SQL example\") \\\n",
    "        .config(\"spark.sql.warehouse.dir\", \"hdfs://localhost:54310/user/hive/warehouse\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# On some clusters the following config setting may be requied\n",
    "#         .config(\"hive.metastore.uris\", \"<value>\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "|        nyse|\n",
      "|      office|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Hive integration\n",
    "spark.sql('show databases').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Hive integration\n",
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.sql('select * from nyse.nysedaily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"append\").saveAsTable(\"nyse.newnyse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+----------------+----------------+---------------+-----------------+------------+---------------------+\n",
      "|stexchange|stock_symbol|stock_date|stock_price_open|stock_price_high|stock_price_low|stock_price_close|stock_volume|stock_price_adj_close|\n",
      "+----------+------------+----------+----------------+----------------+---------------+-----------------+------------+---------------------+\n",
      "|      NYSE|         JEF|  2/8/2010|            25.4|           25.49|          24.78|            24.82|   1134300.0|                24.82|\n",
      "|      NYSE|         JEF|  2/5/2010|           24.91|           25.19|          24.08|            25.01|   1765200.0|                25.01|\n",
      "|      NYSE|         JEF|  2/4/2010|           26.01|            26.2|          24.85|            24.85|   1414400.0|                24.85|\n",
      "|      NYSE|         JEF|  2/3/2010|           26.23|           26.76|          26.22|            26.29|   1066000.0|                26.29|\n",
      "|      NYSE|         JEF|  2/2/2010|           26.08|           26.86|          25.78|            26.46|   1496400.0|                26.46|\n",
      "|      NYSE|         JEF|  2/1/2010|           25.61|           26.11|          25.36|            26.11|   2381800.0|                26.11|\n",
      "|      NYSE|         JEF| 1/29/2010|           26.57|            26.8|          25.41|            25.54|   2010000.0|                25.54|\n",
      "|      NYSE|         JEF| 1/28/2010|            27.4|            27.4|          26.35|            26.36|   1708100.0|                26.36|\n",
      "|      NYSE|         JEF| 1/27/2010|           26.44|           27.15|          26.42|            27.14|   1929700.0|                27.14|\n",
      "|      NYSE|         JEF| 1/26/2010|           26.68|           26.99|          26.46|             26.5|   1422100.0|                 26.5|\n",
      "|      NYSE|         JEF| 1/25/2010|           26.88|           27.17|          26.42|            26.73|   1296300.0|                26.73|\n",
      "|      NYSE|         JEF| 1/22/2010|           26.95|           27.13|          26.48|            26.58|   4806900.0|                26.58|\n",
      "|      NYSE|         JEF| 1/21/2010|           26.91|           27.15|          25.88|             27.0|   4037000.0|                 27.0|\n",
      "|      NYSE|         JEF| 1/20/2010|           25.81|           27.72|          25.51|             26.8|   3740600.0|                 26.8|\n",
      "|      NYSE|         JEF| 1/19/2010|           25.41|           25.94|          25.38|            25.83|   1657700.0|                25.83|\n",
      "|      NYSE|         JEF| 1/15/2010|           25.72|           26.02|          25.13|            25.48|   3198700.0|                25.48|\n",
      "|      NYSE|         JEF| 1/14/2010|            25.4|           25.96|          25.22|            25.82|   2090400.0|                25.82|\n",
      "|      NYSE|         JEF| 1/13/2010|           25.58|           25.62|          25.27|            25.46|   2418900.0|                25.46|\n",
      "|      NYSE|         JEF| 1/12/2010|           25.61|           25.83|          25.35|            25.53|   3174200.0|                25.53|\n",
      "|      NYSE|         JEF| 1/11/2010|           26.08|            26.2|          25.73|            25.93|   1534600.0|                25.93|\n",
      "+----------+------------+----------+----------------+----------------+---------------+-----------------+------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from nyse.newnyse').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+-----------+\n",
      "|database|       tableName|isTemporary|\n",
      "+--------+----------------+-----------+\n",
      "|    nyse|           json2|      false|\n",
      "|    nyse|           json3|      false|\n",
      "|    nyse|         newnyse|      false|\n",
      "|    nyse|       nysedaily|      false|\n",
      "|    nyse|nysedaily_bucket|      false|\n",
      "|    nyse|  nysedaily_part|      false|\n",
      "|    nyse|   nysedividends|      false|\n",
      "|    nyse|            ssg1|      false|\n",
      "|    nyse|       stugrades|      false|\n",
      "+--------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show tables from nyse').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('show tables from jsondemo').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('show tables from mydb').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('use mydb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('select * from tkttbl').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('use jsondemo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('select * from mydb.tkttbl').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM retaildb1.customers1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM retaildb1.products1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cStateCount50 = spark.sql(\"SELECT customer_state, count(*) as state_count FROM retaildb1.customers1 GROUP BY customer_state HAVING state_count>=50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of a Hive query will be a DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cStateCount50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cStateCount50.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cStateCount50.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd200 = spark.sql(\"SELECT category_id, product_category, count(*) as prdcount FROM retaildb1.products1 WHERE product_price>200 GROUP BY category_id, product_category ORDER BY product_category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(prd200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd200.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd200.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These dataframes can be written to Hive tables after creating a new database. The following lines show the syntax. Plesae note that the Hive metastore version should be compatible with the Spark version to be able to create databases and tables in Hive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS retaildb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cStateCount50.coalesce(1).write.saveAsTable(\"retaildb.cStateCount50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prd200.coalesce(1).write.saveAsTable(\"retaildb.prd200\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
